{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd    \n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TextVectorization, LSTM, Dropout, Bidirectional, Dense, Embedding\n",
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the toxic comment dataset (https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('dataset', 'train', 'train.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only comment texts and give them a vector which represent if they are in [toxic, severe_toxic, obscene, threat, insult, identity_hate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df['comment_text']\n",
    "y = df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the number of words we take in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 200000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking words with 1800 length of sentences max , and assign int to them (creating vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=MAX_WORDS, output_sequence_length=1800, output_mode='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build / Train the vectorizer on the comment text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)\n",
    "vectorized_text = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCSHBAP - map, cache, shuffle, batch , prefetch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate result ([toxic, severe_toxic, obscene, threat, insult, identity_hate] as Y and vectorized text as X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitioning our data in train (70%) , validation (20%), test (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.7))\n",
    "validation = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating our model (Sequential Model) who has : An embedding layer, a Bidirectional LSTM layer,  Fully connected layers, and a final sigmoid layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_WORDS+1, 32))\n",
    "model.add(Bidirectional(LSTM(32, activation=\"tanh\")))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(6, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss = 'BinaryCrossentropy', optimizer ='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training our model on 10 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train, epochs = 10, validation_data = validation )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test.as_numpy_iterator().next()\n",
    "input_text = vectorizer(\"U fucker\")\n",
    "res =  model.predict(np.array([input_text]))\n",
    "batch_X, batch_Y  = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()\n",
    "\n",
    "for batch in test.as_numpy_iterator():\n",
    "    X_true, y_true = batch\n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Precision, Recall and Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.04416438192129135, Recall: 0.46023210883140564, Accuracy: 0.004012036137282848\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {pre.result().numpy()}, Recall: {re.result().numpy()}, Accuracy: {acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"toxicity.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('toxicity.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment):\n",
    "    vectorized_comment = vectorizer([comment])\n",
    "    results = model.predict(vectorized_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860/\n",
      "Running on public URL: https://49028.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://49028.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x1fbf1715330>,\n",
       " 'http://127.0.0.1:7860/',\n",
       " 'https://49028.gradio.app')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None(<Task finishe...> result=None>)\n",
      "handle: <Handle>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "interface = gr.Interface(fn=score_comment, inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'), outputs='text')\n",
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6884e110021920ea638b904492cf3d7f5887be5636597d4464e19b6e48044754"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
