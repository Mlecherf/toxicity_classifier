# Toxicity Classifier

A full documented web app that classify text with 6 labels : toxic, severe_toxic, obscene, threat, insult, identity_hate.

Here, the model saved is trained on 10 epochs, and the data is taken from https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview
